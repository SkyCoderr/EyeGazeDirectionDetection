{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation_EyeFaceRelativePosition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHNw62HyDZ67",
        "colab_type": "text"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WbOZk65DOfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import numpy\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVWeyyI3fQf",
        "colab_type": "text"
      },
      "source": [
        "# **Mount Cloud Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZzub5ONEzPH",
        "colab_type": "code",
        "outputId": "ce5f3c2f-7834-4d39-cb2c-3e088b06a4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99mfUWXF3ioj",
        "colab_type": "text"
      },
      "source": [
        "# **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoDG01ABY_64",
        "colab_type": "code",
        "outputId": "c7b71ee7-c5ec-45ea-e799-0cded0fe1615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/My Drive/model8.h5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND_3oTg_wYcr",
        "colab_type": "text"
      },
      "source": [
        "# **Load Data from Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaxavI_wXnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders = [0, 30, 60, 90, 120, 150, 180, -30, -60, -90, -120, -150]\n",
        "CLASSES = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,-10,-20,-30,-40,-50,-60,-70,-80,-90,-100,-110,-120,-130,-140,-150,-160,-170]\n",
        "evaluation = []\n",
        "X_ev = []\n",
        "y_ev = []\n",
        "\n",
        "\n",
        "for folder in folders:\n",
        "  path = '/content/drive/My Drive/ImageEvaluations/ImageEvaluation_EyeFaceRelativePosition'\n",
        "  path = os.path.join(path, str(folder))\n",
        "  index = CLASSES.index(folder)\n",
        "  for image in os.listdir(path):\n",
        "    img = cv2.imread(os.path.join(path, image), 0)\n",
        "    img = cv2.resize(img/255, (100,100))\n",
        "    evaluation.append([img, index])\n",
        "\n",
        "\n",
        "random.shuffle(evaluation)\n",
        "\n",
        "\n",
        "for img, label in evaluation:\n",
        "  X_ev.append(img)\n",
        "  y_ev.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35KBynp7KdM4",
        "colab_type": "text"
      },
      "source": [
        "# **Process Data Loaded**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrjOnWRVKcaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = len(X_ev)\n",
        "\n",
        "\n",
        "X_ev = numpy.array(X_ev).reshape(length, 100, 100, 1)\n",
        "\n",
        "\n",
        "y_evaluation = [None]*length\n",
        "for i in range(length):\n",
        "  li = [0]*36\n",
        "  index = y_ev[i]\n",
        "  li[index] = 1\n",
        "  y_evaluation[i] = li\n",
        "y_ev = y_evaluation\n",
        "\n",
        "\n",
        "y_ev = numpy.array(y_ev).reshape(length, 36)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYhCVErg5Ms7",
        "colab_type": "text"
      },
      "source": [
        "# **Pickle Data onto Cloud Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi3EO1Lq5SeD",
        "colab_type": "code",
        "outputId": "21df4aa8-dc38-434c-e514-8ffddcd4acc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out = open('/content/drive/My Drive/Data/X_ev_EyeFaceRelativePosition.pickle', 'wb')\n",
        "pickle.dump(X_ev, out)\n",
        "out.close\n",
        "\n",
        "out = open('/content/drive/My Drive/Data/y_ev_EyeFaceRelativePosition.pickle', 'wb')\n",
        "pickle.dump(y_ev, out)\n",
        "out.close"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function BufferedWriter.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B3kPijr3-4j",
        "colab_type": "text"
      },
      "source": [
        "# **Load Data from Pickle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFDddFJ14CZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ev_pickle = open('/content/drive/My Drive/Data/X_ev_EyeFaceRelativePosition.pickle', 'rb')\n",
        "X_ev = pickle.load(X_ev_pickle)\n",
        "\n",
        "y_ev_pickle = open('/content/drive/My Drive/Data/y_ev_EyeFaceRelativePosition.pickle', 'rb')\n",
        "y_ev = pickle.load(y_ev_pickle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3E8eDHC6GFT",
        "colab_type": "text"
      },
      "source": [
        "# **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx85WsWl6Cys",
        "colab_type": "code",
        "outputId": "638f1a0c-6960-4611-fde9-6ea15edf760d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_ev, y_ev)\n",
        "print(loss)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 4s 11ms/sample - loss: 67.8383 - acc: 0.0000e+00\n",
            "67.83826724393869\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQhi6UVyqy6R",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy for Each Class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NPOKyLsN1v7",
        "colab_type": "text"
      },
      "source": [
        "Tolerance is a variable defined to limit the roughness of an accurate prediction. For example, for an image of class 60, a tolerance equal to 20 would mean that predictions in [40, 50, 60, 70, 80] would all be correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcl26cDdq4rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,-10,-20,-30,-40,-50,-60,-70,-80,-90,-100,-110,-120,-130,-140,-150,-160,-170]\n",
        "tolerance = 2\n",
        "\n",
        "\n",
        "def normalise(value):\n",
        "  if value > 180:\n",
        "    return value - 360\n",
        "  elif value <= -180:\n",
        "    return value + 360\n",
        "  else:\n",
        "    return value   \n",
        "\n",
        "\n",
        "def in_range(actual, expected, scale):\n",
        "  li = [expected]\n",
        "  for i in range(scale+1):\n",
        "    value1 = normalise(expected + 10*i)\n",
        "    value2 = normalise(expected - 10*i)\n",
        "    li = li + [value1]\n",
        "    li = li + [value2]\n",
        "  if actual in li:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "def class_accuracy(folder):\n",
        "  correct = 0\n",
        "  false = 0\n",
        "  path = '/content/drive/My Drive/ImageEvaluations/ImageEvaluation_EyeFaceRelativePosition'\n",
        "  path = os.path.join(path, str(folder))\n",
        "  wrong_images = []\n",
        "  for image in os.listdir(path):\n",
        "    img = cv2.imread(os.path.join(path, image), 0)\n",
        "    img = cv2.resize(img/255, (100,100))\n",
        "    img = numpy.array(img).reshape(1, 100, 100, 1)\n",
        "    predictions = model.predict(img)[0].tolist()\n",
        "    index = predictions.index(max(predictions))\n",
        "    if in_range(CLASSES[index], folder, tolerance):\n",
        "      correct += 1\n",
        "    else:\n",
        "      false += 1\n",
        "      wrong_images.append(os.path.join(str(folder), image))\n",
        "  accuracy = correct/(correct+false)\n",
        "  return correct, false, wrong_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1td9wfjdq9Ms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "38f05695-7534-4900-d658-877b76715169"
      },
      "source": [
        "folders = [0, 30, 60, 90, 120, 150, 180, -30, -60, -90, -120, -150]\n",
        "wrong_predictions = []\n",
        "total_correct = 0\n",
        "total_false = 0\n",
        "\n",
        "\n",
        "for folder in folders:\n",
        "  correct, false, wrong_images = class_accuracy(folder)\n",
        "  total_correct = total_correct + correct\n",
        "  total_false = total_false + false\n",
        "  print(folder, correct/(correct+false))\n",
        "  wrong_predictions = wrong_predictions + wrong_images\n",
        "print('overall', total_correct/(total_correct+total_false))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.42105263157894735\n",
            "30 0.4\n",
            "60 0.0\n",
            "90 0.0\n",
            "120 0.0\n",
            "150 0.0\n",
            "180 0.0\n",
            "-30 0.7021276595744681\n",
            "-60 0.5666666666666667\n",
            "-90 0.21875\n",
            "-120 0.0\n",
            "-150 0.08\n",
            "overall 0.23148148148148148\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}